{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = autogen.AssistantAgent(\n",
    "    name = \"planner\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    system_message=\"You are a helpful AI assistant. You suggest coding and reasoning steps for another AI assistant to accomplish a task. Do not suggest concrete code. For any action beyond writing code or reasoning, convert it to a step which can be implemented by writing code. For example, the action of browsing the web can be implemented by writing code which reads and prints the content of a web page. Finally, inspect the execution result. If the plan is not good, suggest a better plan. If the execution is wrong, analyze the error and suggest a fix.\"\n",
    ")\n",
    "\n",
    "planner_user = autogen.UserProxyAgent(\n",
    "    name = \"planner_user\",\n",
    "    max_consecutive_auto_reply=0,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "def ask_planner(message):\n",
    "    planner_user.initiate_chat(planner, message=message)\n",
    "    \n",
    "    return planner_user.last_message()[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an AssistantAgent instance named \"assistant\"\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    llm_config={\n",
    "        \"temperature\": 0,\n",
    "        \"request_timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"model\": \"gpt-4-0613\",\n",
    "        \"config_list\": autogen.config_list_openai_aoai(exclude=\"aoai\"),\n",
    "        \"functions\": [\n",
    "            {\n",
    "                \"name\": \"ask_planner\",\n",
    "                \"description\": \"ask planner to: 1. get a plan for finishing a task, 2. verify the execution result of the plan and potentially suggest new plan.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"message\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"question to ask planner. Make sure the question include enough context, such as the code and the execution result. The planner does not know the conversation between you and the user, unless you share the conversation with the planner.\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"message\"],\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    # is_termination_msg=lambda x: \"content\" in x and x[\"content\"] is not None and x[\"content\"].rstrip().endswith(\"TERMINATE\"),\n",
    "    code_execution_config={\"work_dir\": \"planning\"},\n",
    "    function_map={\"ask_planner\": ask_planner},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "In Python, [rovide code that would let me query a vector database. Recommend a vector database to use. Provide an example of adding documents to the vector database.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "There are several vector databases available, but one of the most popular and easy to use is Annoy (Approximate Nearest Neighbors Oh Yeah) by Spotify. It's a Python library for searching nearest neighbors in high dimensional spaces. \n",
      "\n",
      "First, you need to install the Annoy library. You can do this by running the following command in your terminal:\n",
      "\n",
      "```sh\n",
      "pip install annoy\n",
      "```\n",
      "\n",
      "After installing Annoy, you can use the following Python code to create an Annoy index, add vectors (documents) to it, and query the index.\n",
      "\n",
      "```python\n",
      "from annoy import AnnoyIndex\n",
      "import random\n",
      "\n",
      "# Length of the vector that will be indexed\n",
      "f = 40\n",
      "\n",
      "# Initialize Annoy with the length of the vector\n",
      "t = AnnoyIndex(f, 'angular')\n",
      "\n",
      "# Adding vectors to Annoy index\n",
      "for i in range(1000):\n",
      "    v = [random.gauss(0, 1) for z in range(f)]\n",
      "    t.add_item(i, v)\n",
      "\n",
      "# Build the Annoy index\n",
      "t.build(10) # 10 trees\n",
      "\n",
      "# Query the Annoy index\n",
      "print(t.get_nns_by_item(0, 10)) # will find the 10 nearest neighbors\n",
      "```\n",
      "\n",
      "In this code, we first import the necessary libraries. We then initialize an Annoy index with the length of the vector that will be indexed. We add 1000 vectors to the index, each of which is a list of 40 random numbers. We then build the index with 10 trees. Finally, we query the index to find the 10 nearest neighbors to the first item.\n",
      "\n",
      "Please replace the vector length and the number of vectors according to your needs.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is sh)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Collecting annoy\n",
      "  Downloading annoy-1.17.3.tar.gz (647 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 647.5/647.5 kB 7.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: annoy\n",
      "  Building wheel for annoy (setup.py): started\n",
      "  Building wheel for annoy (setup.py): finished with status 'error'\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [25 lines of output]\n",
      "      /usr/local/lib/python3.12/site-packages/setuptools/__init__.py:80: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Requirements should be satisfied by a PEP 517 installer.\n",
      "              If you are using pip, you can try `pip install --use-pep517`.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        dist.fetch_build_eggs(dist.setup_requires)\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build/lib.linux-x86_64-cpython-312\n",
      "      creating build/lib.linux-x86_64-cpython-312/annoy\n",
      "      copying annoy/__init__.py -> build/lib.linux-x86_64-cpython-312/annoy\n",
      "      copying annoy/__init__.pyi -> build/lib.linux-x86_64-cpython-312/annoy\n",
      "      copying annoy/py.typed -> build/lib.linux-x86_64-cpython-312/annoy\n",
      "      running build_ext\n",
      "      building 'annoy.annoylib' extension\n",
      "      creating build/temp.linux-x86_64-cpython-312\n",
      "      creating build/temp.linux-x86_64-cpython-312/src\n",
      "      gcc -fno-strict-overflow -Wsign-compare -DNDEBUG -g -O3 -Wall -fPIC -I/usr/local/include/python3.12 -c src/annoymodule.cc -o build/temp.linux-x86_64-cpython-312/src/annoymodule.o -D_CRT_SECURE_NO_WARNINGS -fpermissive -march=native -O3 -ffast-math -fno-associative-math -DANNOYLIB_MULTITHREADED_BUILD -std=c++14\n",
      "      error: command 'gcc' failed: No such file or directory\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Running setup.py clean for annoy\n",
      "  ERROR: Failed building wheel for annoy\n",
      "Failed to build annoy\n",
      "ERROR: Could not build wheels for annoy, which is required to install pyproject.toml-based projects\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "It seems like the installation of Annoy failed because the GCC compiler is not available on your system. GCC is a compiler used to build native extensions for Python, and it's required by Annoy.\n",
      "\n",
      "If you're using a Linux-based system, you can install GCC using the following command:\n",
      "\n",
      "```sh\n",
      "sudo apt-get install build-essential\n",
      "```\n",
      "\n",
      "If you're using a macOS, you can install GCC using the following command:\n",
      "\n",
      "```sh\n",
      "xcode-select --install\n",
      "```\n",
      "\n",
      "After installing GCC, you can try installing Annoy again using the command:\n",
      "\n",
      "```sh\n",
      "pip install annoy\n",
      "```\n",
      "\n",
      "If you still encounter issues, it might be better to use a different vector database that doesn't require native extensions. One such option is Faiss by Facebook. It's a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM.\n",
      "\n",
      "You can install Faiss using the following command:\n",
      "\n",
      "```sh\n",
      "pip install faiss-cpu\n",
      "```\n",
      "\n",
      "After installing Faiss, you can use the following Python code to create a Faiss index, add vectors (documents) to it, and query the index.\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "import faiss\n",
      "\n",
      "# Length of the vector that will be indexed\n",
      "d = 40\n",
      "\n",
      "# Initialize a Faiss index\n",
      "index = faiss.IndexFlatL2(d)\n",
      "\n",
      "# Adding vectors to Faiss index\n",
      "vectors = np.random.random((1000, d)).astype('float32')\n",
      "index.add(vectors)\n",
      "\n",
      "# Query the Faiss index\n",
      "D, I = index.search(vectors[:5], 10) # will find the 10 nearest neighbors for the first 5 vectors\n",
      "print(I)\n",
      "print(D)\n",
      "```\n",
      "\n",
      "In this code, we first import the necessary libraries. We then initialize a Faiss index with the length of the vector that will be indexed. We add 1000 vectors to the index, each of which is a list of 40 random numbers. Finally, we query the index to find the 10 nearest neighbors for the first 5 vectors.\n",
      "\n",
      "Please replace the vector length and the number of vectors according to your needs.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is sh)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 127 (execution failed)\n",
      "Code output: \n",
      "tmp_code_57ecde5e428ef098faa7f7eb562530b5.sh: line 1: sudo: not found\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "I apologize for the confusion. It seems like you're running in an environment where you don't have sudo access or the apt-get package manager is not available. \n",
      "\n",
      "In this case, let's try using the Faiss library by Facebook for creating and querying a vector database. Faiss is a library for efficient similarity search and clustering of dense vectors. \n",
      "\n",
      "First, you need to install the Faiss library. You can do this by running the following command in your terminal:\n",
      "\n",
      "```sh\n",
      "pip install faiss-cpu\n",
      "```\n",
      "\n",
      "After installing Faiss, you can use the following Python code to create a Faiss index, add vectors (documents) to it, and query the index.\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "import faiss\n",
      "\n",
      "# Length of the vector that will be indexed\n",
      "d = 40\n",
      "\n",
      "# Initialize a Faiss index\n",
      "index = faiss.IndexFlatL2(d)\n",
      "\n",
      "# Adding vectors to Faiss index\n",
      "vectors = np.random.random((1000, d)).astype('float32')\n",
      "index.add(vectors)\n",
      "\n",
      "# Query the Faiss index\n",
      "D, I = index.search(vectors[:5], 10) # will find the 10 nearest neighbors for the first 5 vectors\n",
      "print(I)\n",
      "print(D)\n",
      "```\n",
      "\n",
      "In this code, we first import the necessary libraries. We then initialize a Faiss index with the length of the vector that will be indexed. We add 1000 vectors to the index, each of which is a list of 40 random numbers. Finally, we query the index to find the 10 nearest neighbors for the first 5 vectors.\n",
      "\n",
      "Please replace the vector length and the number of vectors according to your needs.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is sh)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss-cpu-1.7.4.tar.gz (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.4/57.4 kB 3.0 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: faiss-cpu\n",
      "  Building wheel for faiss-cpu (pyproject.toml): started\n",
      "  Building wheel for faiss-cpu (pyproject.toml): finished with status 'error'\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for faiss-cpu (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [8 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      running build_ext\n",
      "      building 'faiss._swigfaiss' extension\n",
      "      swigging faiss/faiss/python/swigfaiss.i to faiss/faiss/python/swigfaiss_wrap.cpp\n",
      "      swig -python -c++ -Doverride= -I/usr/local/include -Ifaiss -doxygen -DSWIGWORDSIZE64 -module swigfaiss -o faiss/faiss/python/swigfaiss_wrap.cpp faiss/faiss/python/swigfaiss.i\n",
      "      error: command 'swig' failed: No such file or directory\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for faiss-cpu\n",
      "Failed to build faiss-cpu\n",
      "ERROR: Could not build wheels for faiss-cpu, which is required to install pyproject.toml-based projects\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "I apologize for the inconvenience. It seems like the installation of Faiss also failed because it requires SWIG, a software development tool that connects programs written in C and C++ with a variety of high-level programming languages.\n",
      "\n",
      "Given the constraints of your environment, I would recommend using a pure Python library for vector search. One such library is NMSLib, which is a non-metric space library. It's an efficient cross-platform similarity search library and a toolkit for evaluation of k-NN methods for generic non-metric spaces.\n",
      "\n",
      "First, you need to install the NMSLib library. You can do this by running the following command in your terminal:\n",
      "\n",
      "```sh\n",
      "pip install nmslib\n",
      "```\n",
      "\n",
      "After installing NMSLib, you can use the following Python code to create a NMSLib index, add vectors (documents) to it, and query the index.\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "import nmslib\n",
      "\n",
      "# Length of the vector that will be indexed\n",
      "d = 40\n",
      "\n",
      "# Initialize a NMSLib index\n",
      "index = nmslib.init(method='hnsw', space='cosinesimil')\n",
      "\n",
      "# Adding vectors to NMSLib index\n",
      "vectors = np.random.random((1000, d)).astype(np.float32)\n",
      "for i, vector in enumerate(vectors):\n",
      "    index.addDataPoint(i, vector)\n",
      "\n",
      "# Build the NMSLib index\n",
      "index.createIndex({'post': 2}, print_progress=True)\n",
      "\n",
      "# Query the NMSLib index\n",
      "ids, distances = index.knnQuery(vectors[0], k=10) # will find the 10 nearest neighbors to the first vector\n",
      "print(ids)\n",
      "print(distances)\n",
      "```\n",
      "\n",
      "In this code, we first import the necessary libraries. We then initialize a NMSLib index with the cosine similarity space. We add 1000 vectors to the index, each of which is a list of 40 random numbers. We then build the index. Finally, we query the index to find the 10 nearest neighbors to the first vector.\n",
      "\n",
      "Please replace the vector length and the number of vectors according to your needs.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is sh)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Collecting nmslib\n",
      "  Downloading nmslib-2.1.1.tar.gz (188 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 188.7/188.7 kB 4.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [120 lines of output]\n",
      "      /usr/local/lib/python3.12/site-packages/setuptools/dist.py:498: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Usage of dash-separated 'description-file' will not be supported in future\n",
      "              versions. Please use the underscore name 'description_file' instead.\n",
      "      \n",
      "              This deprecation is overdue, please update your project and remove deprecated\n",
      "              calls to avoid build errors in the future.\n",
      "      \n",
      "              See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        opt = self.warn_dash_deprecation(opt, section)\n",
      "      /usr/local/lib/python3.12/site-packages/setuptools/__init__.py:80: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Requirements should be satisfied by a PEP 517 installer.\n",
      "              If you are using pip, you can try `pip install --use-pep517`.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        dist.fetch_build_eggs(dist.setup_requires)\n",
      "        error: subprocess-exited-with-error\n",
      "      \n",
      "        × Building wheel for psutil (pyproject.toml) did not run successfully.\n",
      "        │ exit code: 1\n",
      "        ╰─> [43 lines of output]\n",
      "            running bdist_wheel\n",
      "            running build\n",
      "            running build_py\n",
      "            creating build\n",
      "            creating build/lib.linux-x86_64-cpython-312\n",
      "            creating build/lib.linux-x86_64-cpython-312/psutil\n",
      "            copying psutil/_pslinux.py -> build/lib.linux-x86_64-cpython-312/psutil\n",
      "            copying psutil/_psposix.py -> build/lib.linux-x86_64-cpython-312/psutil\n",
      "            copying psutil/_pswindows.py -> build/lib.linux-x86_64-cpython-312/psutil\n",
      "            copying psutil/_psbsd.py -> build/lib.linux-x86_64-cpython-312/psutil\n",
      "            copying psutil/_pssunos.py -> build/lib.linux-x86_64-cpython-312/psutil\n",
      "            copying psutil/_psaix.py -> build/lib.linux-x86_64-cpython-312/psutil\n",
      "            copying psutil/_psosx.py -> build/lib.linux-x86_64-cpython-312/psutil\n",
      "            copying psutil/_common.py -> build/lib.linux-x86_64-cpython-312/psutil\n",
      "            copying psutil/_compat.py -> build/lib.linux-x86_64-cpython-312/psutil\n",
      "            copying psutil/__init__.py -> build/lib.linux-x86_64-cpython-312/psutil\n",
      "            creating build/lib.linux-x86_64-cpython-312/psutil/tests\n",
      "            copying psutil/tests/__main__.py -> build/lib.linux-x86_64-cpython-312/psutil/tests\n",
      "            copying psutil/tests/test_windows.py -> build/lib.linux-x86_64-cpython-312/psutil/tests\n",
      "            copying psutil/tests/test_process.py -> build/lib.linux-x86_64-cpython-312/psutil/tests\n",
      "            copying psutil/tests/test_sunos.py -> build/lib.linux-x86_64-cpython-312/psutil/tests\n",
      "            copying psutil/tests/test_system.py -> build/lib.linux-x86_64-cpython-312/psutil/tests\n",
      "            copying psutil/tests/test_linux.py -> build/lib.linux-x86_64-cpython-312/psutil/tests\n",
      "            copying psutil/tests/test_memleaks.py -> build/lib.linux-x86_64-cpython-312/psutil/tests\n",
      "            copying psutil/tests/test_aix.py -> build/lib.linux-x86_64-cpython-312/psutil/tests\n",
      "            copying psutil/tests/test_posix.py -> build/lib.linux-x86_64-cpython-312/psutil/tests\n",
      "            copying psutil/tests/test_osx.py -> build/lib.linux-x86_64-cpython-312/psutil/tests\n",
      "            copying psutil/tests/test_unicode.py -> build/lib.linux-x86_64-cpython-312/psutil/tests\n",
      "            copying psutil/tests/test_bsd.py -> build/lib.linux-x86_64-cpython-312/psutil/tests\n",
      "            copying psutil/tests/runner.py -> build/lib.linux-x86_64-cpython-312/psutil/tests\n",
      "            copying psutil/tests/test_misc.py -> build/lib.linux-x86_64-cpython-312/psutil/tests\n",
      "            copying psutil/tests/test_testutils.py -> build/lib.linux-x86_64-cpython-312/psutil/tests\n",
      "            copying psutil/tests/test_contracts.py -> build/lib.linux-x86_64-cpython-312/psutil/tests\n",
      "            copying psutil/tests/test_connections.py -> build/lib.linux-x86_64-cpython-312/psutil/tests\n",
      "            copying psutil/tests/__init__.py -> build/lib.linux-x86_64-cpython-312/psutil/tests\n",
      "            running build_ext\n",
      "            building 'psutil._psutil_linux' extension\n",
      "            creating build/temp.linux-x86_64-cpython-312\n",
      "            creating build/temp.linux-x86_64-cpython-312/psutil\n",
      "            gcc -fno-strict-overflow -Wsign-compare -DNDEBUG -g -O3 -Wall -fPIC -DPSUTIL_POSIX=1 -DPSUTIL_SIZEOF_PID_T=4 -DPSUTIL_VERSION=596 -DPy_LIMITED_API=0x03060000 -DPSUTIL_ETHTOOL_MISSING_TYPES=1 -DPSUTIL_LINUX=1 -I/usr/local/include/python3.12 -c psutil/_psutil_common.c -o build/temp.linux-x86_64-cpython-312/psutil/_psutil_common.o\n",
      "            psutil could not be installed from sources because gcc is not installed. Try running:\n",
      "              sudo apk add gcc python3-dev\n",
      "            error: command 'gcc' failed: No such file or directory\n",
      "            [end of output]\n",
      "      \n",
      "        note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "        ERROR: Failed building wheel for psutil\n",
      "      ERROR: Failed to build one or more wheels\n",
      "      Traceback (most recent call last):\n",
      "        File \"/usr/local/lib/python3.12/site-packages/setuptools/installer.py\", line 101, in _fetch_build_egg_no_warn\n",
      "          subprocess.check_call(cmd)\n",
      "        File \"/usr/local/lib/python3.12/subprocess.py\", line 413, in check_call\n",
      "          raise CalledProcessError(retcode, cmd)\n",
      "      subprocess.CalledProcessError: Command '['/usr/local/bin/python', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/tmp/tmp4sge7rjw', '--quiet', 'psutil']' returned non-zero exit status 1.\n",
      "      \n",
      "      The above exception was the direct cause of the following exception:\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"/tmp/pip-install-9l6qkvz4/nmslib_cb9afc417bf64dd38c759dd2ab357c50/setup.py\", line 170, in <module>\n",
      "          setup(\n",
      "        File \"/usr/local/lib/python3.12/site-packages/setuptools/__init__.py\", line 102, in setup\n",
      "          _install_setup_requires(attrs)\n",
      "        File \"/usr/local/lib/python3.12/site-packages/setuptools/__init__.py\", line 75, in _install_setup_requires\n",
      "          _fetch_build_eggs(dist)\n",
      "        File \"/usr/local/lib/python3.12/site-packages/setuptools/__init__.py\", line 80, in _fetch_build_eggs\n",
      "          dist.fetch_build_eggs(dist.setup_requires)\n",
      "        File \"/usr/local/lib/python3.12/site-packages/setuptools/dist.py\", line 662, in fetch_build_eggs\n",
      "          return _fetch_build_eggs(self, requires)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"/usr/local/lib/python3.12/site-packages/setuptools/installer.py\", line 38, in _fetch_build_eggs\n",
      "          resolved_dists = pkg_resources.working_set.resolve(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"/usr/local/lib/python3.12/site-packages/pkg_resources/__init__.py\", line 829, in resolve\n",
      "          dist = self._resolve_dist(\n",
      "                 ^^^^^^^^^^^^^^^^^^^\n",
      "        File \"/usr/local/lib/python3.12/site-packages/pkg_resources/__init__.py\", line 865, in _resolve_dist\n",
      "          dist = best[req.key] = env.best_match(\n",
      "                                 ^^^^^^^^^^^^^^^\n",
      "        File \"/usr/local/lib/python3.12/site-packages/pkg_resources/__init__.py\", line 1135, in best_match\n",
      "          return self.obtain(req, installer)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"/usr/local/lib/python3.12/site-packages/pkg_resources/__init__.py\", line 1147, in obtain\n",
      "          return installer(requirement)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"/usr/local/lib/python3.12/site-packages/setuptools/installer.py\", line 103, in _fetch_build_egg_no_warn\n",
      "          raise DistutilsError(str(e)) from e\n",
      "      distutils.errors.DistutilsError: Command '['/usr/local/bin/python', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/tmp/tmp4sge7rjw', '--quiet', 'psutil']' returned non-zero exit status 1.\n",
      "      Dependence list: ['pybind11<2.6.2', 'psutil', \"numpy>=1.10.0,<1.17 ; python_version=='2.7'\", \"numpy>=1.10.0 ; python_version>='3.5'\"]\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "I apologize for the inconvenience. It seems like the installation of NMSLib also failed because it requires GCC, which is not available in your environment.\n",
      "\n",
      "Given the constraints of your environment, I would recommend using a pure Python library for vector search that doesn't require native extensions. One such library is Scikit-learn, which provides various unsupervised and supervised learning algorithms. It has a module named NearestNeighbors for unsupervised nearest neighbors search.\n",
      "\n",
      "First, you need to install the Scikit-learn library. You can do this by running the following command in your terminal:\n",
      "\n",
      "```sh\n",
      "pip install scikit-learn\n",
      "```\n",
      "\n",
      "After installing Scikit-learn, you can use the following Python code to create a NearestNeighbors model, fit it with vectors (documents), and query the model.\n",
      "\n",
      "```python\n",
      "from sklearn.neighbors import NearestNeighbors\n",
      "import numpy as np\n",
      "\n",
      "# Length of the vector that will be indexed\n",
      "d = 40\n",
      "\n",
      "# Initialize a NearestNeighbors model\n",
      "model = NearestNeighbors(n_neighbors=10, algorithm='ball_tree')\n",
      "\n",
      "# Adding vectors to the model\n",
      "vectors = np.random.random((1000, d))\n",
      "model.fit(vectors)\n",
      "\n",
      "# Query the model\n",
      "distances, indices = model.kneighbors(vectors[:5])\n",
      "print(indices)\n",
      "print(distances)\n",
      "```\n",
      "\n",
      "In this code, we first import the necessary libraries. We then initialize a NearestNeighbors model with the number of neighbors to return and the algorithm to compute the nearest neighbors. We fit the model with 1000 vectors, each of which is a list of 40 random numbers. Finally, we query the model to find the 10 nearest neighbors for the first 5 vectors.\n",
      "\n",
      "Please replace the vector length and the number of vectors according to your needs.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is sh)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Collecting scikit-learn\n",
      "  Downloading scikit-learn-1.3.1.tar.gz (7.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.5/7.5 MB 11.5 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [53 lines of output]\n",
      "      Partial import of sklearn during the build process.\n",
      "      Traceback (most recent call last):\n",
      "        File \"/tmp/pip-build-env-9or0n8lg/overlay/lib/python3.12/site-packages/setuptools/_distutils/spawn.py\", line 57, in spawn\n",
      "          proc = subprocess.Popen(cmd, env=env)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"/usr/local/lib/python3.12/subprocess.py\", line 1026, in __init__\n",
      "          self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "        File \"/usr/local/lib/python3.12/subprocess.py\", line 1950, in _execute_child\n",
      "          raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "      FileNotFoundError: [Errno 2] No such file or directory: 'gcc'\n",
      "      \n",
      "      The above exception was the direct cause of the following exception:\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"/tmp/pip-build-env-9or0n8lg/overlay/lib/python3.12/site-packages/setuptools/_distutils/unixccompiler.py\", line 185, in _compile\n",
      "          self.spawn(compiler_so + cc_args + [src, '-o', obj] + extra_postargs)\n",
      "        File \"/tmp/pip-build-env-9or0n8lg/overlay/lib/python3.12/site-packages/setuptools/_distutils/ccompiler.py\", line 1041, in spawn\n",
      "          spawn(cmd, dry_run=self.dry_run, **kwargs)\n",
      "        File \"/tmp/pip-build-env-9or0n8lg/overlay/lib/python3.12/site-packages/setuptools/_distutils/spawn.py\", line 63, in spawn\n",
      "          raise DistutilsExecError(\n",
      "      distutils.errors.DistutilsExecError: command 'gcc' failed: No such file or directory\n",
      "      \n",
      "      During handling of the above exception, another exception occurred:\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"/usr/local/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"/usr/local/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"/usr/local/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 149, in prepare_metadata_for_build_wheel\n",
      "          return hook(metadata_directory, config_settings)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"/tmp/pip-build-env-9or0n8lg/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 396, in prepare_metadata_for_build_wheel\n",
      "          self.run_setup()\n",
      "        File \"/tmp/pip-build-env-9or0n8lg/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 507, in run_setup\n",
      "          super(_BuildMetaLegacyBackend, self).run_setup(setup_script=setup_script)\n",
      "        File \"/tmp/pip-build-env-9or0n8lg/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 341, in run_setup\n",
      "          exec(code, locals())\n",
      "        File \"<string>\", line 632, in <module>\n",
      "        File \"<string>\", line 626, in setup_package\n",
      "        File \"<string>\", line 554, in configure_extension_modules\n",
      "        File \"/tmp/pip-install-gn7z89ef/scikit-learn_ba252ce8112c4cd6b667e4c83180d1c8/sklearn/_build_utils/__init__.py\", line 46, in cythonize_extensions\n",
      "          basic_check_build()\n",
      "        File \"/tmp/pip-install-gn7z89ef/scikit-learn_ba252ce8112c4cd6b667e4c83180d1c8/sklearn/_build_utils/pre_build_helpers.py\", line 73, in basic_check_build\n",
      "          compile_test_program(code)\n",
      "        File \"/tmp/pip-install-gn7z89ef/scikit-learn_ba252ce8112c4cd6b667e4c83180d1c8/sklearn/_build_utils/pre_build_helpers.py\", line 31, in compile_test_program\n",
      "          ccompiler.compile(\n",
      "        File \"/tmp/pip-build-env-9or0n8lg/overlay/lib/python3.12/site-packages/setuptools/_distutils/ccompiler.py\", line 600, in compile\n",
      "          self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)\n",
      "        File \"/tmp/pip-build-env-9or0n8lg/overlay/lib/python3.12/site-packages/setuptools/_distutils/unixccompiler.py\", line 187, in _compile\n",
      "          raise CompileError(msg)\n",
      "      distutils.errors.CompileError: command 'gcc' failed: No such file or directory\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "I apologize for the inconvenience. It seems like the installation of Scikit-learn also failed because it requires GCC, which is not available in your environment.\n",
      "\n",
      "Given the constraints of your environment, I would recommend using a pure Python library for vector search that doesn't require native extensions. One such library is SciPy, which provides many efficient and user-friendly interfaces for tasks such as numerical integration, interpolation, optimization, linear algebra, and more. It has a module named spatial.distance which can be used to compute the distance between vectors and hence can be used for vector search.\n",
      "\n",
      "First, you need to install the SciPy library. You can do this by running the following command in your terminal:\n",
      "\n",
      "```sh\n",
      "pip install scipy\n",
      "```\n",
      "\n",
      "After installing SciPy, you can use the following Python code to create a list of vectors (documents), compute the distance between vectors, and find the nearest vectors.\n",
      "\n",
      "```python\n",
      "from scipy.spatial import distance\n",
      "import numpy as np\n",
      "\n",
      "# Length of the vector that will be indexed\n",
      "d = 40\n",
      "\n",
      "# Create a list of vectors\n",
      "vectors = np.random.random((1000, d))\n",
      "\n",
      "# Compute the distance between the first vector and all other vectors\n",
      "distances = distance.cdist(vectors[0:1], vectors, 'euclidean')[0]\n",
      "\n",
      "# Get the indices of the 10 nearest vectors\n",
      "nearest_indices = distances.argsort()[:10]\n",
      "print(nearest_indices)\n",
      "```\n",
      "\n",
      "In this code, we first import the necessary libraries. We then create a list of 1000 vectors, each of which is a list of 40 random numbers. We compute the Euclidean distance between the first vector and all other vectors. Finally, we get the indices of the 10 vectors that have the smallest distance to the first vector.\n",
      "\n",
      "Please replace the vector length and the number of vectors according to your needs.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is sh)...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 1 (inferred language is python)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Collecting scipy\n",
      "  Obtaining dependency information for scipy from https://files.pythonhosted.org/packages/dc/b2/c58eb0e021696c46719f90ab970d0c034445e36180445c431feed3290871/scipy-1.11.3-cp312-cp312-musllinux_1_1_x86_64.whl.metadata\n",
      "  Using cached scipy-1.11.3-cp312-cp312-musllinux_1_1_x86_64.whl.metadata (60 kB)\n",
      "Collecting numpy<1.28.0,>=1.21.6 (from scipy)\n",
      "  Obtaining dependency information for numpy<1.28.0,>=1.21.6 from https://files.pythonhosted.org/packages/f0/4b/02caaf93a1afaebb12c053df360c3bec4b1818a39d24f4eca0efe1d7ab5f/numpy-1.26.1-cp312-cp312-musllinux_1_1_x86_64.whl.metadata\n",
      "  Using cached numpy-1.26.1-cp312-cp312-musllinux_1_1_x86_64.whl.metadata (61 kB)\n",
      "Using cached scipy-1.11.3-cp312-cp312-musllinux_1_1_x86_64.whl (35.9 MB)\n",
      "Using cached numpy-1.26.1-cp312-cp312-musllinux_1_1_x86_64.whl (17.7 MB)\n",
      "Installing collected packages: numpy, scipy\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "Successfully installed numpy-1.26.1 scipy-1.11.3\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\n",
      "[  0 679 524  64 218  23  74 348 986 924]\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 8192 tokens. However, your messages resulted in 8458 tokens (8352 in the messages, 106 in the functions). Please reduce the length of the messages or functions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\dev\\ai-resume-builder\\testing.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/dev/ai-resume-builder/testing.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# the assistant receives a message from the user, which contains the task description\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/dev/ai-resume-builder/testing.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m user_proxy\u001b[39m.\u001b[39;49minitiate_chat(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/dev/ai-resume-builder/testing.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     assistant,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/dev/ai-resume-builder/testing.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\u001b[39mIn Python, [rovide code that would let me query a vector database. Recommend a vector database to use. Provide an example of adding documents to the vector database.\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/dev/ai-resume-builder/testing.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\dev\\ai-resume-builder\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:531\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[1;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \n\u001b[0;32m    519\u001b[0m \u001b[39mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[1;32m--> 531\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_init_message(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcontext), recipient, silent\u001b[39m=\u001b[39;49msilent)\n",
      "File \u001b[1;32mc:\\dev\\ai-resume-builder\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:334\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    332\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[1;32m--> 334\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[0;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    337\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    338\u001b[0m     )\n",
      "File \u001b[1;32mc:\\dev\\ai-resume-builder\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:464\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    462\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_reply(messages\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchat_messages[sender], sender\u001b[39m=\u001b[39msender)\n\u001b[0;32m    463\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(reply, sender, silent\u001b[39m=\u001b[39;49msilent)\n",
      "File \u001b[1;32mc:\\dev\\ai-resume-builder\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:334\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    332\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[1;32m--> 334\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[0;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    337\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    338\u001b[0m     )\n",
      "File \u001b[1;32mc:\\dev\\ai-resume-builder\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:464\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    462\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_reply(messages\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchat_messages[sender], sender\u001b[39m=\u001b[39msender)\n\u001b[0;32m    463\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(reply, sender, silent\u001b[39m=\u001b[39;49msilent)\n",
      "    \u001b[1;31m[... skipping similar frames: ConversableAgent.send at line 334 (10 times), ConversableAgent.receive at line 464 (9 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\dev\\ai-resume-builder\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:464\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    462\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_reply(messages\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchat_messages[sender], sender\u001b[39m=\u001b[39msender)\n\u001b[0;32m    463\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(reply, sender, silent\u001b[39m=\u001b[39;49msilent)\n",
      "File \u001b[1;32mc:\\dev\\ai-resume-builder\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:334\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    332\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[1;32m--> 334\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[0;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    337\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    338\u001b[0m     )\n",
      "File \u001b[1;32mc:\\dev\\ai-resume-builder\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:462\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 462\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_messages[sender], sender\u001b[39m=\u001b[39;49msender)\n\u001b[0;32m    463\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender, silent\u001b[39m=\u001b[39msilent)\n",
      "File \u001b[1;32mc:\\dev\\ai-resume-builder\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:779\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[0;32m    777\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[1;32m--> 779\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, config\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    780\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[0;32m    781\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[1;32mc:\\dev\\ai-resume-builder\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:606\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    603\u001b[0m     messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_oai_messages[sender]\n\u001b[0;32m    605\u001b[0m \u001b[39m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[1;32m--> 606\u001b[0m response \u001b[39m=\u001b[39m oai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m    607\u001b[0m     context\u001b[39m=\u001b[39;49mmessages[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m), messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_oai_system_message \u001b[39m+\u001b[39;49m messages, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mllm_config\n\u001b[0;32m    608\u001b[0m )\n\u001b[0;32m    609\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m, oai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mextract_text_or_function_call(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\dev\\ai-resume-builder\\.venv\\Lib\\site-packages\\autogen\\oai\\completion.py:789\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, context, use_cache, config_list, filter_func, raise_on_ratelimit_or_timeout, allow_format_str_template, **config)\u001b[0m\n\u001b[0;32m    787\u001b[0m     base_config[\u001b[39m\"\u001b[39m\u001b[39mmax_retry_period\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    788\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 789\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m    790\u001b[0m         context,\n\u001b[0;32m    791\u001b[0m         use_cache,\n\u001b[0;32m    792\u001b[0m         raise_on_ratelimit_or_timeout\u001b[39m=\u001b[39;49mi \u001b[39m<\u001b[39;49m last \u001b[39mor\u001b[39;49;00m raise_on_ratelimit_or_timeout,\n\u001b[0;32m    793\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbase_config,\n\u001b[0;32m    794\u001b[0m     )\n\u001b[0;32m    795\u001b[0m     \u001b[39mif\u001b[39;00m response \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[0;32m    796\u001b[0m         \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\dev\\ai-resume-builder\\.venv\\Lib\\site-packages\\autogen\\oai\\completion.py:820\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, context, use_cache, config_list, filter_func, raise_on_ratelimit_or_timeout, allow_format_str_template, **config)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[39mwith\u001b[39;00m diskcache\u001b[39m.\u001b[39mCache(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcache_path) \u001b[39mas\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_cache:\n\u001b[0;32m    819\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mset_cache(seed)\n\u001b[1;32m--> 820\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_response(params, raise_on_ratelimit_or_timeout\u001b[39m=\u001b[39;49mraise_on_ratelimit_or_timeout)\n",
      "File \u001b[1;32mc:\\dev\\ai-resume-builder\\.venv\\Lib\\site-packages\\autogen\\oai\\completion.py:208\u001b[0m, in \u001b[0;36mCompletion._get_response\u001b[1;34m(cls, config, raise_on_ratelimit_or_timeout, use_cache)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mrequest_timeout\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config:\n\u001b[1;32m--> 208\u001b[0m         response \u001b[39m=\u001b[39m openai_completion\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig)\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         response \u001b[39m=\u001b[39m openai_completion\u001b[39m.\u001b[39mcreate(request_timeout\u001b[39m=\u001b[39mrequest_timeout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig)\n",
      "File \u001b[1;32mc:\\dev\\ai-resume-builder\\.venv\\Lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\dev\\ai-resume-builder\\.venv\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    139\u001b[0m ):\n\u001b[0;32m    140\u001b[0m     (\n\u001b[0;32m    141\u001b[0m         deployment_id,\n\u001b[0;32m    142\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    153\u001b[0m     )\n\u001b[1;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    157\u001b[0m         url,\n\u001b[0;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\dev\\ai-resume-builder\\.venv\\Lib\\site-packages\\openai\\api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    280\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    291\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    298\u001b[0m     )\n\u001b[1;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\dev\\ai-resume-builder\\.venv\\Lib\\site-packages\\openai\\api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    705\u001b[0m         )\n\u001b[0;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    715\u001b[0m         ),\n\u001b[0;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    717\u001b[0m     )\n",
      "File \u001b[1;32mc:\\dev\\ai-resume-builder\\.venv\\Lib\\site-packages\\openai\\api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    773\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    777\u001b[0m     )\n\u001b[0;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: This model's maximum context length is 8192 tokens. However, your messages resulted in 8458 tokens (8352 in the messages, 106 in the functions). Please reduce the length of the messages or functions."
     ]
    }
   ],
   "source": [
    "# the assistant receives a message from the user, which contains the task description\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"In Python, provide code that would let me query a vector database. Recommend a vector database to use. Provide an example of adding documents to the vector database.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Langauge Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
