{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, Tool, initialize_agent, AgentExecutor\n",
    "from langchain.agents.openai_assistant import OpenAIAssistantRunnable\n",
    "from langchain.tools import Tool, BaseTool\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from typing import Type\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from SparksAI import config\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseTool().run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_agent(prompt:str) -> str:\n",
    "    print(\"Generating Image!\")\n",
    "    \n",
    "    response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=prompt,\n",
    "        size=\"1024x1024\",\n",
    "        quality=\"standard\",\n",
    "    )\n",
    "    \n",
    "    return response.data[0].url\n",
    "\n",
    "class image_agent_input(BaseModel):\n",
    "    \"\"\"Input for image_agent\"\"\"\n",
    "    \n",
    "    prompt: str = Field(description=\"Prompt used to generated image. Should be as detailed as possible.\")\n",
    "    \n",
    "class image_agent_tool(BaseTool):\n",
    "    name = \"image_agent\"\n",
    "    description = \"Used to generate an image based on a prompt. The prompt should be as detailed as possible. It will return the url to the image.\"\n",
    "    \n",
    "    args_schema: Type[BaseModel] = image_agent_input\n",
    "    \n",
    "    def _run(self, prompt: str) -> str:\n",
    "        return image_agent(prompt)\n",
    "    \n",
    "    def _arun(self, prompt: str) -> str:\n",
    "        raise NotImplementedError(\"image_agent does not support async\")\n",
    "\n",
    "def research_agent(prompt: str) -> str:\n",
    "    print(\"Generating Research Report\")\n",
    "    return \"The best answer to this question is: The test was successful\"\n",
    "\n",
    "class research_agent_input(BaseModel):\n",
    "    \"\"\"Input for research_agent\"\"\"\n",
    "    \n",
    "    prompt: str = Field(description=\"Topic for agent to research. Should be target to provide information needed to answer users question.\")\n",
    "    \n",
    "class research_agent_tool(BaseTool):\n",
    "    name = \"research_agent\"\n",
    "    description = \"Used to generate a research report on a topic. The topic should be as detailed as possible and targeted to answer the users questions.\"\n",
    "    \n",
    "    args_schema: Type[BaseModel] = research_agent_input\n",
    "    \n",
    "    def _run(self, prompt: str) -> str:\n",
    "        return research_agent(prompt)\n",
    "    \n",
    "    def _arun(self, prompt: str) -> str:\n",
    "        raise NotImplementedError(\"research_agent does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "       image_agent_tool(),\n",
    "       research_agent_tool() \n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_decider = OpenAIAssistantRunnable.create_assistant(\n",
    "    name=\"decider\",\n",
    "    instructions=\"\"\"You process requests and determine which agent is best placed to answer the request.\n",
    "    You have two choices:\n",
    "    1. image_agent\n",
    "        - This agent will generate images based on a prompt. \n",
    "        - The response will be a url to the image generated.\n",
    "    \n",
    "    2. research_agent\n",
    "       - This agent will generate a research report on a given topic.\n",
    "       - The response will be a report on a given research topic.\n",
    "       \n",
    "    If you don't know which agent should be used ask for clarifying information.\n",
    "    \"\"\",\n",
    "    tools=tools,\n",
    "    model=config.MODEL_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Image!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://oaidalleapiprodscus.blob.core.windows.net/private/org-u6tXutztghSbkd6Q9d75T29A/user-GMFCuEaaDr21mSosDjPB5qSr/img-0GpGSHtD7AQju944gSe9kstm.png?st=2023-11-25T02%3A29%3A39Z&se=2023-11-25T04%3A29%3A39Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-11-24T12%3A30%3A08Z&ske=2023-11-25T12%3A30%3A08Z&sks=b&skv=2021-08-06&sig=jaUayvZ/n/j7gduGcHMC1qtv%2BzHEGnuW1BJJy0cfNm8%3D'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_agent_tool().run({\"prompt\": \"A white fox running along side the river during winter\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_decider = OpenAIAssistantRunnable(assistant_id=\"asst_weo12rBKGXdH4kyHihU8AYpk\", as_agent=True)\n",
    "\n",
    "runable = AgentExecutor(agent=ai_decider, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0mGenerating Image!\n",
      "\u001b[36;1m\u001b[1;3mhttps://oaidalleapiprodscus.blob.core.windows.net/private/org-u6tXutztghSbkd6Q9d75T29A/user-GMFCuEaaDr21mSosDjPB5qSr/img-WTwGtCRJqJRkrmeeeeJsWlPj.png?st=2023-11-25T02%3A30%3A43Z&se=2023-11-25T04%3A30%3A43Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-11-25T00%3A40%3A30Z&ske=2023-11-26T00%3A40%3A30Z&sks=b&skv=2021-08-06&sig=CvHNxgHVvf00PtiJEgGdS2W9vHuosDehoD1jh5sjcdA%3D\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'content': 'Please create an image of a white fox running along side the river during winter',\n",
       " 'output': 'Here is an image of a white fox running alongside a river during winter:\\n\\n![White Fox Running Alongside a River During Winter](https://oaidalleapiprodscus.blob.core.windows.net/private/org-u6tXutztghSbkd6Q9d75T29A/user-GMFCuEaaDr21mSosDjPB5qSr/img-WTwGtCRJqJRkrmeeeeJsWlPj.png?st=2023-11-25T02%3A30%3A43Z&se=2023-11-25T04%3A30%3A43Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-11-25T00%3A40%3A30Z&ske=2023-11-26T00%3A40%3A30Z&sks=b&skv=2021-08-06&sig=CvHNxgHVvf00PtiJEgGdS2W9vHuosDehoD1jh5sjcdA%3D)'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runable.invoke({\"content\": \"Please create an image of a white fox running along side the river during winter\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0mGenerating Research Report\n",
      "\u001b[33;1m\u001b[1;3mThe best answer to this question is: The test was successful\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0mGenerating Research Report\n",
      "\u001b[33;1m\u001b[1;3mThe best answer to this question is: The test was successful\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'content': 'How do you use langchain to develop OpenAI assistants?',\n",
       " 'output': \"I apologize for the confusion, but it seems there was an issue in retrieving the relevant information. Let me try that again to provide you with a detailed report on how to use Langchain to develop OpenAI assistants. Please hold on for a moment while I process your request.\\nThere seems to be a persistent issue with obtaining information about Langchain and its usage for developing OpenAI assistants. Unfortunately, I am unable to provide you with a detailed report at this time. However, if you're interested in learning about Langchain, it is a toolchain designed to make it easier to develop language applications using LLMs (large language models) like GPT-3.\\n\\nDeveloping OpenAI assistants with Langchain would generally involve understanding Langchain's APIs and integrating them with OpenAI's GPT-3 APIs to create custom language-based applications. This might require knowledge in software development, API usage, and potentially machine learning concepts.\\n\\nFor detailed instructions and a step-by-step guide, I would recommend looking into Langchain's documentation, available resources, or tutorials that might guide you through the development process. If you have any specific questions about the development process, please feel free to ask, and I will do my best to assist you.\"}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runable.invoke({\"content\": \"How do you use langchain to develop OpenAI assistants?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'System: You are Tav\\nHuman: Test Input\\nAI: This is hard, I should plan well'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import OpenAIMultiFunctionsAgent\n",
    "from langchain.schema import SystemMessage, AIMessage\n",
    "\n",
    "prompt = OpenAIMultiFunctionsAgent.create_prompt(system_message=SystemMessage(content=\"You are Tav\"))\n",
    "\n",
    "prompt.format(**{\"input\": \"Test Input\", \"agent_scratchpad\": [AIMessage(content=\"This is hard, I should plan well\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SparksAI.async_helpers import AreturnMessageIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = AreturnMessageIterator(\"testsdsfsdfsdf\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'AreturnMessageIterator' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\dev\\sparks-ai\\experiment_decider_agent.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/dev/sparks-ai/experiment_decider_agent.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m test:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/dev/sparks-ai/experiment_decider_agent.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39;49m(i)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'AreturnMessageIterator' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i in test:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SparksAI import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResearchAgentTool()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools.ResearchAgentTool()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
